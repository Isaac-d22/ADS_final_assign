{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0b1e4a6f",
      "metadata": {
        "id": "0b1e4a6f"
      },
      "source": [
        "# Assessment for Advanced Data Science\n",
        "\n",
        "## Christian Cabrera, Radzim Sendyka, Carl Henrik Ek and Neil D. Lawrence\n",
        "\n",
        "### 6th November 2023\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7856d1b",
      "metadata": {
        "id": "d7856d1b"
      },
      "source": [
        "Welcome to the course assessment for the Advanced Data Science unit. In this assessment you will build a prediction system for UK house prices.\n",
        "\n",
        "Your prediction system will be based on data from the UK Price Paid data available [here](https://www.gov.uk/government/statistical-data-sets/price-paid-data-downloads). By combining this data with the UK Office for National Statistics data on the latitude/longitude of postcodes (available [here](https://www.getthedata.com/open-postcode-geo)) you will have a record of house prices and their approximate latitude/longitude. Due to the size of these data you will use a relational database to handle them.  \n",
        "\n",
        "To make predictions of the house price you will augment your data with information obtained from Open Street Map: an open license source of mapping information. You will use the techniques you have learnt in the course to indentify and incorporate useful features for house price prediction.\n",
        "\n",
        "\n",
        "\n",
        "Alongside your implementation you will provide a short repository overview describing how you have implemented the different parts of the project and where you have placed those parts in your code repository. You will submit your code alongside a version of this notebook that will allow your examiner to understand and reconstruct the thinking behind your analysis. This notebook is structured to help you in creating that description and allow you to understand how we will allocate the marks. You should make use of the Fynesse framework (<https://github.com/lawrennd/fynesse_template>) for structuring your code.\n",
        "\n",
        "Remember the notebook you create should *tell a story*, any code that is not critical to that story can safely be placed into the associated analysis library and imported for use (structured as given in the Fynesse template)\n",
        "\n",
        "The maximum total mark for this assessment is 20. That mark is split into Three Questions below, each worth 5 marks each. Then a final 5 marks will be given for the quality, structure and reusability of the code and analysis you produce giving 20 marks in total. At the end, we would like to know your experience using LLMs in this assignment.\n",
        "\n",
        "### Important Note:\n",
        "\n",
        "*Some tasks in this assignment require you to develop skills for searching for multiple solutions and trying different things. This environment recreates industrial data science and software engineering problems. There is no one right answer.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb7e7c53",
      "metadata": {
        "id": "bb7e7c53"
      },
      "source": [
        "### Useful Links\n",
        "\n",
        "You may find some of the following links useful when building your system.\n",
        "\n",
        "University instuctions on Security and Privacy with AWS.\n",
        "\n",
        "https://help.uis.cam.ac.uk/service/network-services/hosting-services/AWS/aws-security-privacy\n",
        "\n",
        "Security Rules in AWS\n",
        "\n",
        "https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_VPC.Scenarios.html#USER_VPC.Scenario4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d3ee6ce",
      "metadata": {
        "id": "9d3ee6ce"
      },
      "source": [
        "### Installing Your Library\n",
        "\n",
        "One artefact to be included in your submission is a python library structured according to the \"Access, Assess, Address\" standard for data science solutions. You will submit this library alongside your code. Use the cell below to perform the necessary installation instructions for your library.\n",
        "\n",
        "You should base your module on the template repository given by the Fynesse template repository. That should make it `pip` installable as below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "13f71cb7",
      "metadata": {
        "id": "13f71cb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting git+https://github.com/Isaac-d22/ADS_final_assign.git\n",
            "  Cloning https://github.com/Isaac-d22/ADS_final_assign.git to /private/var/folders/k3/ghfh_db95gd3y5y75qb_s8v40000gn/T/pip-req-build-pmjnkazi\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Isaac-d22/ADS_final_assign.git /private/var/folders/k3/ghfh_db95gd3y5y75qb_s8v40000gn/T/pip-req-build-pmjnkazi\n",
            "  Resolved https://github.com/Isaac-d22/ADS_final_assign.git to commit 7f44c55296910da8654d76e658761d32f5424186\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (from fynesse==0.1.0) (2.1.1)\n",
            "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from fynesse==0.1.0) (1.26.1)\n",
            "Requirement already satisfied: jupyter in /opt/homebrew/lib/python3.11/site-packages (from fynesse==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.11/site-packages (from fynesse==0.1.0) (3.8.0)\n",
            "Requirement already satisfied: notebook in /opt/homebrew/lib/python3.11/site-packages (from jupyter->fynesse==0.1.0) (7.0.6)\n",
            "Requirement already satisfied: qtconsole in /opt/homebrew/lib/python3.11/site-packages (from jupyter->fynesse==0.1.0) (5.4.4)\n",
            "Requirement already satisfied: jupyter-console in /opt/homebrew/lib/python3.11/site-packages (from jupyter->fynesse==0.1.0) (6.6.3)\n",
            "Requirement already satisfied: nbconvert in /opt/homebrew/lib/python3.11/site-packages (from jupyter->fynesse==0.1.0) (7.10.0)\n",
            "Requirement already satisfied: ipykernel in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from jupyter->fynesse==0.1.0) (6.21.1)\n",
            "Requirement already satisfied: ipywidgets in /opt/homebrew/lib/python3.11/site-packages (from jupyter->fynesse==0.1.0) (8.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->fynesse==0.1.0) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->fynesse==0.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->fynesse==0.1.0) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->fynesse==0.1.0) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from matplotlib->fynesse==0.1.0) (23.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->fynesse==0.1.0) (10.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->fynesse==0.1.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from matplotlib->fynesse==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas->fynesse==0.1.0) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas->fynesse==0.1.0) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->fynesse==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: appnope in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter->fynesse==0.1.0) (0.1.3)\n",
            "Requirement already satisfied: comm>=0.1.1 in /opt/homebrew/lib/python3.11/site-packages (from ipykernel->jupyter->fynesse==0.1.0) (0.1.4)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter->fynesse==0.1.0) (1.6.6)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter->fynesse==0.1.0) (8.9.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter->fynesse==0.1.0) (8.0.2)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter->fynesse==0.1.0) (5.2.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter->fynesse==0.1.0) (0.1.6)\n",
            "Requirement already satisfied: nest-asyncio in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter->fynesse==0.1.0) (1.5.6)\n",
            "Requirement already satisfied: psutil in /opt/homebrew/lib/python3.11/site-packages (from ipykernel->jupyter->fynesse==0.1.0) (5.9.6)\n",
            "Requirement already satisfied: pyzmq>=17 in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter->fynesse==0.1.0) (25.0.0)\n",
            "Requirement already satisfied: tornado>=6.1 in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter->fynesse==0.1.0) (6.2)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter->fynesse==0.1.0) (5.9.0)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.9 in /opt/homebrew/lib/python3.11/site-packages (from ipywidgets->jupyter->fynesse==0.1.0) (4.0.9)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /opt/homebrew/lib/python3.11/site-packages (from ipywidgets->jupyter->fynesse==0.1.0) (3.0.9)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0.30 in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from jupyter-console->jupyter->fynesse==0.1.0) (3.0.36)\n",
            "Requirement already satisfied: pygments in /opt/homebrew/lib/python3.11/site-packages (from jupyter-console->jupyter->fynesse==0.1.0) (2.16.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /opt/homebrew/lib/python3.11/site-packages (from nbconvert->jupyter->fynesse==0.1.0) (4.12.2)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /opt/homebrew/lib/python3.11/site-packages (from nbconvert->jupyter->fynesse==0.1.0) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /opt/homebrew/lib/python3.11/site-packages (from nbconvert->jupyter->fynesse==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /opt/homebrew/lib/python3.11/site-packages (from nbconvert->jupyter->fynesse==0.1.0) (3.1.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /opt/homebrew/lib/python3.11/site-packages (from nbconvert->jupyter->fynesse==0.1.0) (0.2.2)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from nbconvert->jupyter->fynesse==0.1.0) (2.1.3)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/homebrew/lib/python3.11/site-packages (from nbconvert->jupyter->fynesse==0.1.0) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /opt/homebrew/lib/python3.11/site-packages (from nbconvert->jupyter->fynesse==0.1.0) (0.8.0)\n",
            "Requirement already satisfied: nbformat>=5.7 in /opt/homebrew/lib/python3.11/site-packages (from nbconvert->jupyter->fynesse==0.1.0) (5.9.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/homebrew/lib/python3.11/site-packages (from nbconvert->jupyter->fynesse==0.1.0) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /opt/homebrew/lib/python3.11/site-packages (from nbconvert->jupyter->fynesse==0.1.0) (1.2.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/homebrew/lib/python3.11/site-packages (from notebook->jupyter->fynesse==0.1.0) (2.9.1)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in /opt/homebrew/lib/python3.11/site-packages (from notebook->jupyter->fynesse==0.1.0) (2.25.0)\n",
            "Requirement already satisfied: jupyterlab<5,>=4.0.2 in /opt/homebrew/lib/python3.11/site-packages (from notebook->jupyter->fynesse==0.1.0) (4.0.8)\n",
            "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /opt/homebrew/lib/python3.11/site-packages (from notebook->jupyter->fynesse==0.1.0) (0.2.3)\n",
            "Requirement already satisfied: ipython-genutils in /opt/homebrew/lib/python3.11/site-packages (from qtconsole->jupyter->fynesse==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: qtpy>=2.4.0 in /opt/homebrew/lib/python3.11/site-packages (from qtconsole->jupyter->fynesse==0.1.0) (2.4.1)\n",
            "Requirement already satisfied: webencodings in /opt/homebrew/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter->fynesse==0.1.0) (0.5.1)\n",
            "Requirement already satisfied: backcall in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from ipython>=7.23.1->ipykernel->jupyter->fynesse==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: decorator in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from ipython>=7.23.1->ipykernel->jupyter->fynesse==0.1.0) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from ipython>=7.23.1->ipykernel->jupyter->fynesse==0.1.0) (0.18.2)\n",
            "Requirement already satisfied: pickleshare in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from ipython>=7.23.1->ipykernel->jupyter->fynesse==0.1.0) (0.7.5)\n",
            "Requirement already satisfied: stack-data in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from ipython>=7.23.1->ipykernel->jupyter->fynesse==0.1.0) (0.6.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from ipython>=7.23.1->ipykernel->jupyter->fynesse==0.1.0) (4.8.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter->fynesse==0.1.0) (2.6.2)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /opt/homebrew/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->fynesse==0.1.0) (4.0.0)\n",
            "Requirement already satisfied: argon2-cffi in /opt/homebrew/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->fynesse==0.1.0) (23.1.0)\n",
            "Requirement already satisfied: jupyter-events>=0.6.0 in /opt/homebrew/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->fynesse==0.1.0) (0.8.0)\n",
            "Requirement already satisfied: jupyter-server-terminals in /opt/homebrew/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->fynesse==0.1.0) (0.4.4)\n",
            "Requirement already satisfied: overrides in /opt/homebrew/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->fynesse==0.1.0) (7.4.0)\n",
            "Requirement already satisfied: prometheus-client in /opt/homebrew/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->fynesse==0.1.0) (0.18.0)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /opt/homebrew/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->fynesse==0.1.0) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /opt/homebrew/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->fynesse==0.1.0) (0.17.1)\n",
            "Requirement already satisfied: websocket-client in /opt/homebrew/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->fynesse==0.1.0) (1.6.4)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /opt/homebrew/lib/python3.11/site-packages (from jupyterlab<5,>=4.0.2->notebook->jupyter->fynesse==0.1.0) (2.0.4)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from jupyterlab<5,>=4.0.2->notebook->jupyter->fynesse==0.1.0) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.10 in /opt/homebrew/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->fynesse==0.1.0) (2.13.1)\n",
            "Requirement already satisfied: json5>=0.9.0 in /opt/homebrew/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->fynesse==0.1.0) (0.9.14)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /opt/homebrew/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->fynesse==0.1.0) (4.19.2)\n",
            "Requirement already satisfied: requests>=2.31 in /opt/homebrew/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->fynesse==0.1.0) (2.31.0)\n",
            "Requirement already satisfied: fastjsonschema in /opt/homebrew/lib/python3.11/site-packages (from nbformat>=5.7->nbconvert->jupyter->fynesse==0.1.0) (2.18.1)\n",
            "Requirement already satisfied: wcwidth in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->fynesse==0.1.0) (0.2.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/lib/python3.11/site-packages (from beautifulsoup4->nbconvert->jupyter->fynesse==0.1.0) (2.5)\n",
            "Requirement already satisfied: idna>=2.8 in /opt/homebrew/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter->fynesse==0.1.0) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter->fynesse==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->fynesse==0.1.0) (0.8.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->fynesse==0.1.0) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->fynesse==0.1.0) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->fynesse==0.1.0) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->fynesse==0.1.0) (0.10.6)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/homebrew/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter->fynesse==0.1.0) (2.0.7)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /opt/homebrew/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter->fynesse==0.1.0) (6.0.1)\n",
            "Requirement already satisfied: rfc3339-validator in /opt/homebrew/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter->fynesse==0.1.0) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/homebrew/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter->fynesse==0.1.0) (0.1.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter->fynesse==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter->fynesse==0.1.0) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter->fynesse==0.1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter->fynesse==0.1.0) (2023.7.22)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /opt/homebrew/lib/python3.11/site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter->fynesse==0.1.0) (21.2.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->fynesse==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->fynesse==0.1.0) (2.2.1)\n",
            "Requirement already satisfied: pure-eval in /Users/isaacdiarrassouba/Library/Python/3.11/lib/python/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->fynesse==0.1.0) (0.2.2)\n",
            "Requirement already satisfied: fqdn in /opt/homebrew/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->fynesse==0.1.0) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /opt/homebrew/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->fynesse==0.1.0) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->fynesse==0.1.0) (2.4)\n",
            "Requirement already satisfied: uri-template in /opt/homebrew/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->fynesse==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=1.11 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->fynesse==0.1.0) (1.13)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter->fynesse==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /opt/homebrew/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter->fynesse==0.1.0) (2.21)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /opt/homebrew/lib/python3.11/site-packages (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->fynesse==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/homebrew/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->fynesse==0.1.0) (2.8.19.14)\n",
            "Building wheels for collected packages: fynesse\n",
            "  Building wheel for fynesse (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for fynesse: filename=fynesse-0.1.0-py3-none-any.whl size=6700 sha256=00ae69a20dcd79a8d8c47c816672c8a484c40b1285895dd1a0b1efcaf0631107\n",
            "  Stored in directory: /private/var/folders/k3/ghfh_db95gd3y5y75qb_s8v40000gn/T/pip-ephem-wheel-cache-fawvk0f1/wheels/44/d2/2b/aa60f5b3b9d3f03677269c649c3ddede72eb859989075dbb39\n",
            "Successfully built fynesse\n",
            "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: fynesse\n",
            "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed fynesse-0.1.0\n",
            "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/six-1.16.0-py3.11.egg-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install your library here, for example the fynesse template\n",
        "# is set up to be pip installable\n",
        "%pip install git+https://github.com/Isaac-d22/ADS_final_assign.git"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2fafca0",
      "metadata": {
        "id": "c2fafca0"
      },
      "source": [
        "Your own library should be installed in the line above, then you can import it as usual (where you can either replace `fynesse` with the name you've given your analysis module or you can leave the name as `fynesse` as you prefer)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "db162b53",
      "metadata": {
        "id": "db162b53"
      },
      "outputs": [],
      "source": [
        "import fynesse.access as access\n",
        "import yaml\n",
        "import csv\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from ipywidgets import interact_manual, Text, Password"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4f29c755",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__spec__',\n",
              " 'config',\n",
              " 'create_connection',\n",
              " 'data',\n",
              " 'default_file',\n",
              " 'download_csv',\n",
              " 'equal_condition',\n",
              " 'file',\n",
              " 'greater_condition',\n",
              " 'greater_equal_condition',\n",
              " 'item',\n",
              " 'key',\n",
              " 'local_file',\n",
              " 'not_equal_condition',\n",
              " 'os',\n",
              " 'populate_table',\n",
              " 'pymysql',\n",
              " 'query_table',\n",
              " 'requests',\n",
              " 'user_file',\n",
              " 'yaml',\n",
              " 'zipfile']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(access)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26533cf6",
      "metadata": {
        "id": "26533cf6"
      },
      "source": [
        "## Question 1. Accessing a Database of House Prices, Latitudes and Longitudes\n",
        "\n",
        "The UK price paid data for housing dates back to 1995 and contains millions of transactions. The size of the data makes it unwieldy to manipulate directly in python frameworks such as `pandas`. As a result we will host the data in a *relational database*.\n",
        "\n",
        "Using the following ideas.\n",
        "\n",
        "1. A cloud hosted database (such as MariaDB hosted on the AWS RDS service).\n",
        "2. The SQL language wrapped in appropriately structured python code.\n",
        "3. Joining of two databases.\n",
        "\n",
        "You will construct a database containing tables that contain all house prices, latitudes and longitudes from the UK house price data base since 1995.\n",
        "\n",
        "You will likely find the following resources helpful.\n",
        "\n",
        "1. Lecture 1, 2 and 3.\n",
        "2. Lab class 1 and 2.\n",
        "3. The UK Price Paid data for houses: <https://www.gov.uk/government/statistical-data-sets/price-paid-data-downloads>\n",
        "4. The UK ONS Data base of postcode latitude and longitudes:  <https://www.getthedata.com/open-postcode-geo>\n",
        "\n",
        "Below we provide codeboxes and hints to help you develop your answer.\n",
        "\n",
        "### Important Notes:\n",
        "\n",
        "*The main knowledge you need to do a first pass through this question will have been taught by the end of Lab Session 2 (31st October 2023). You will likely want to review your answer as part of **refactoring** your code  and analysis pipeline shortly before hand in.*\n",
        "\n",
        "*We recommend doing Question 1 as early as possible to avoid being blocked from important work given that uploading the data can take long.*\n",
        "\n",
        "*If you encounter problems with the online notebook (e.g., interrupted connections with the AWS server), you can use a local IDE to work in your machine.*\n",
        "\n",
        "*5 Marks*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd689312",
      "metadata": {
        "id": "fd689312"
      },
      "source": [
        "### Task A\n",
        "\n",
        "Set up the database. You'll need to set up a database on AWS. You were guided in how to do this in the lab sessions. You should be able to use the same database instance you created in the lab, or you can delete that and start with a fresh instance. You'll remember from the lab that the database requires credentials (username, password) to access. It's good practice to store those credentials *outside* the notebook so you don't accidentally share them by e.g. checking code into a repository.\n",
        "  \n",
        "Call the database you use for this assessment `property_prices`.\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "feaf09b9",
      "metadata": {
        "id": "feaf09b9"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'interact_manual' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/isaacdiarrassouba/Desktop/Part II/Advanced Data Science/Final assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Write code for requesting and storing credentials (username, password) here.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# No need to run this cell if credentials.yaml file has already been populated (will be the case as I have included it in my submission)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m@interact_manual\u001b[39m(username\u001b[39m=\u001b[39mText(description\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsername:\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                  password\u001b[39m=\u001b[39mPassword(description\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassword:\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrite_credentials\u001b[39m(username, password):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcredentials.yaml\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         credentials_dict \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39musername\u001b[39m\u001b[39m'\u001b[39m: username,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                             \u001b[39m'\u001b[39m\u001b[39mpassword\u001b[39m\u001b[39m'\u001b[39m: password}\n",
            "\u001b[0;31mNameError\u001b[0m: name 'interact_manual' is not defined"
          ]
        }
      ],
      "source": [
        "# Write code for requesting and storing credentials (username, password) here.\n",
        "# No need to run this cell if credentials.yaml file has already been populated (will be the case as I have included it in my submission)\n",
        "@interact_manual(username=Text(description=\"Username:\"),\n",
        "                 password=Password(description=\"Password:\"))\n",
        "def write_credentials(username, password):\n",
        "    with open(\"credentials.yaml\", \"w\") as file:\n",
        "        credentials_dict = {'username': username,\n",
        "                            'password': password}\n",
        "        yaml.dump(credentials_dict, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "036c419d",
      "metadata": {
        "id": "036c419d"
      },
      "outputs": [],
      "source": [
        "# Write any other setup code you need for setting up database access here.\n",
        "database_details = {\"url\": \"database-ads-id373.cgrre17yxw11.eu-west-2.rds.amazonaws.com\",\n",
        "                    \"port\": 3306,\n",
        "                    \"name\": 'property_prices'}\n",
        "with open(\"credentials.yaml\") as file:\n",
        "  credentials = yaml.safe_load(file)\n",
        "username = credentials[\"username\"]\n",
        "password = credentials[\"password\"]\n",
        "url = database_details[\"url\"]\n",
        "port = database_details[\"port\"]\n",
        "db_name = database_details[\"name\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "183dc338",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Establishing a connection and creating the property_prices database\n",
        "conn = access.create_connection(user=username, password=password, host=url, port=port)\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {db_name} DEFAULT CHARACTER SET utf8 COLLATE utf8_bin;\")\n",
        "conn.commit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "1bae0b31",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check to see that the database property_prices was successfully created (1 for successful 0 for unsuccessful)\n",
        "cursor.execute(f\"SHOW DATABASES LIKE '{db_name}';\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33c7237f",
      "metadata": {
        "id": "33c7237f"
      },
      "source": [
        "### Task B\n",
        "\n",
        "Create a database table called `pp_data` containing all the UK Price Paid data from the [gov.uk site](https://www.gov.uk/government/statistical-data-sets/price-paid-data-downloads). You'll need to prepare a new table to receive the data and upload the UK Price Paid data to your database instance. The total data is over 3 gigabytes in size. We suggest that rather than downloading the full data in CSV format, you use the fact that they have split the data into years and into different parts per year. For example, the first part of the data for 2018 is stored at <http://prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-2018-part1.csv>. Each of these files is less than 100MB and can be downloaded very quickly to local disk, then uploaded using\n",
        "\n",
        "\n",
        "```\n",
        "LOAD DATA LOCAL INFILE 'filename' INTO TABLE `table_name`\n",
        "FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED by '\"'\n",
        "LINES STARTING BY '' TERMINATED BY '\\n';\n",
        "```\n",
        "*Note* this command should be wrapped and placed in an appropriately structured python module.\n",
        "\n",
        "Each 'data part' should be downloadable from the `gov.uk` site. It should take around 5 minutes to download the whole dataset. By looping across the years and different parts, you should be able to robustly upload this large data set to your database instance in around 15 minutes. You should get a table with 28'258,161 rows. ***Note: A select count of the table can take more than half an hour.***\n",
        "\n",
        "You may find the following schema useful in the creation of your table:\n",
        "\n",
        "```\n",
        "--\n",
        "-- Table structure for table `pp_data`\n",
        "--\n",
        "DROP TABLE IF EXISTS `pp_data`;\n",
        "CREATE TABLE IF NOT EXISTS `pp_data` (\n",
        "  `transaction_unique_identifier` tinytext COLLATE utf8_bin NOT NULL,\n",
        "  `price` int(10) unsigned NOT NULL,\n",
        "  `date_of_transfer` date NOT NULL,\n",
        "  `postcode` varchar(8) COLLATE utf8_bin NOT NULL,\n",
        "  `property_type` varchar(1) COLLATE utf8_bin NOT NULL,\n",
        "  `new_build_flag` varchar(1) COLLATE utf8_bin NOT NULL,\n",
        "  `tenure_type` varchar(1) COLLATE utf8_bin NOT NULL,\n",
        "  `primary_addressable_object_name` tinytext COLLATE utf8_bin NOT NULL,\n",
        "  `secondary_addressable_object_name` tinytext COLLATE utf8_bin NOT NULL,\n",
        "  `street` tinytext COLLATE utf8_bin NOT NULL,\n",
        "  `locality` tinytext COLLATE utf8_bin NOT NULL,\n",
        "  `town_city` tinytext COLLATE utf8_bin NOT NULL,\n",
        "  `district` tinytext COLLATE utf8_bin NOT NULL,\n",
        "  `county` tinytext COLLATE utf8_bin NOT NULL,\n",
        "  `ppd_category_type` varchar(2) COLLATE utf8_bin NOT NULL,\n",
        "  `record_status` varchar(2) COLLATE utf8_bin NOT NULL,\n",
        "  `db_id` bigint(20) unsigned NOT NULL\n",
        ") DEFAULT CHARSET=utf8 COLLATE=utf8_bin AUTO_INCREMENT=1 ;\n",
        "```\n",
        "This schema is written by Dale Potter and can be found on Github here: <https://github.com/dalepotter/uk_property_price_data/blob/master/create_db.sql>\n",
        "\n",
        "You may also find it helpful to set up the following primary key to the `pp_data` table. This should be done before uploading your data.\n",
        "\n",
        "```\n",
        "--\n",
        "-- Primary key for table `pp_data`\n",
        "--\n",
        "ALTER TABLE `pp_data`\n",
        "ADD PRIMARY KEY (`db_id`);\n",
        "\n",
        "ALTER TABLE `pp_data`\n",
        "MODIFY db_id bigint(20) unsigned NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=1;\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e789b174",
      "metadata": {
        "id": "e789b174"
      },
      "source": [
        "In the box below, briefly describe what the schema is doing."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7d9d674",
      "metadata": {
        "id": "d7d9d674"
      },
      "source": [
        "First a check is performed to determine whether a pp_data table already exists and if it does, it drops (i.e. deletes) that table from the database. The schema itself defines the fields of the table which are simply a one-to-one mapping with the columns in the csv. Each of these columns is given a type (i.e. int(10) which corresponds to an unsigned integer with a maximum value of 10 decimal digits, 4294967295 to be precise). The NOT NULL constraint that you see means that records cannot be inserted if they have a NULL value in this field and so for this schema all fields must be populated. COLLATE defines the set of rules used for string ordering and comparison in this schema utf8_bin is used. The DEFAULT here simply specifies what character set and collation function should be used if one hasn't been specified for a text field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "92da8c96",
      "metadata": {
        "id": "92da8c96"
      },
      "outputs": [],
      "source": [
        "# Code to download the files in parts and store them in a directory\n",
        "if not os.path.exists(\"house_price_data\"):\n",
        "    os.makedirs(\"house_price_data\")\n",
        "    \n",
        "URL_PREFIX = \"http://prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/\"\n",
        "for i in range(1995, 2024):\n",
        "    part1 = f\"pp-{i}-part1.csv\"\n",
        "    part2 = f\"pp-{i}-part2.csv\"\n",
        "    access.download_csv(url=(URL_PREFIX + part1), filename=part1, target_dir=\"house_price_data\")\n",
        "    access.download_csv(url=(URL_PREFIX + part2), filename=part2, target_dir=\"house_price_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "df979351",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code to create table and set primary key\n",
        "conn = access.create_connection(user=username, password=password, host=url, port=port, database=db_name)\n",
        "access.create_pp_data(conn)\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bfdee21d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code to populate pp_data table with downloaded csv data\n",
        "for i in range(1995, 2024):\n",
        "    part1 = f\"house_price_data/pp-{i}-part1.csv\"\n",
        "    part2 = f\"house_price_data/pp-{i}-part2.csv\"\n",
        "    access.populate_table(conn=conn, filename=part1, table=\"pp_data\")\n",
        "    access.populate_table(conn=conn, filename=part2, table=\"pp_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "aa3b3585",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(('{FAC30767-09BA-5E20-E053-4704A8C004EE}',\n",
              "  229000,\n",
              "  datetime.date(2023, 3, 7),\n",
              "  'E17 4GD',\n",
              "  'F',\n",
              "  'N',\n",
              "  'L',\n",
              "  'CANNOCK COURT, 3',\n",
              "  'FLAT 69',\n",
              "  'HAWKER PLACE',\n",
              "  '',\n",
              "  'LONDON',\n",
              "  'WALTHAM FOREST',\n",
              "  'GREATER LONDON',\n",
              "  'A',\n",
              "  'A',\n",
              "  30500000),)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Since our primary key just increments we can check that the database has been populated successfully by taking a number in the region of 28 million. \n",
        "# I have a bit over 30.5 million entires in my table which is reasonable and I believe the reason for the difference is the fact that I am using as much data as is available to me.\n",
        "# Given the recent regime shift in terms of interest rates my prior is that making use of the 2023 data will aid the model signifcantly in making predictions of prices over the past 6 months\n",
        "access.query_table(conn=conn, table='pp_data', conditions=[access.equal_condition('db_id', 30500000)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb9ece66",
      "metadata": {
        "id": "bb9ece66"
      },
      "source": [
        "### Task C\n",
        "\n",
        "Create a database table called `postcode_data` containing the ONS Postcode information. <GetTheData.com> has organised data derived from the UK Office for National Statistics into a convenient CSV file. You can find details [here](https://www.getthedata.com/open-postcode-geo).\n",
        "\n",
        "\n",
        "The data you need can be found at this url: <https://www.getthedata.com/downloads/open_postcode_geo.csv.zip>. It will need to be unzipped before use. Downloading and unzipping the data should not take more than 10 seconds.\n",
        "\n",
        "You may find the following schema useful for the postcode data (developed by Christian and Neil)\n",
        "\n",
        "```\n",
        "USE `property_prices`;\n",
        "--\n",
        "-- Table structure for table `postcode_data`\n",
        "--\n",
        "DROP TABLE IF EXISTS `postcode_data`;\n",
        "CREATE TABLE IF NOT EXISTS `postcode_data` (\n",
        "  `postcode` varchar(8) COLLATE utf8_bin NOT NULL,\n",
        "  `status` enum('live','terminated') NOT NULL,\n",
        "  `usertype` enum('small', 'large') NOT NULL,\n",
        "  `easting` int unsigned,\n",
        "  `northing` int unsigned,\n",
        "  `positional_quality_indicator` int NOT NULL,\n",
        "  `country` enum('England', 'Wales', 'Scotland', 'Northern Ireland', 'Channel Islands', 'Isle of Man') NOT NULL,\n",
        "  `latitude` decimal(11,8) NOT NULL,\n",
        "  `longitude` decimal(10,8) NOT NULL,\n",
        "  `postcode_no_space` tinytext COLLATE utf8_bin NOT NULL,\n",
        "  `postcode_fixed_width_seven` varchar(7) COLLATE utf8_bin NOT NULL,\n",
        "  `postcode_fixed_width_eight` varchar(8) COLLATE utf8_bin NOT NULL,\n",
        "  `postcode_area` varchar(2) COLLATE utf8_bin NOT NULL,\n",
        "  `postcode_district` varchar(4) COLLATE utf8_bin NOT NULL,\n",
        "  `postcode_sector` varchar(6) COLLATE utf8_bin NOT NULL,\n",
        "  `outcode` varchar(4) COLLATE utf8_bin NOT NULL,\n",
        "  `incode` varchar(3)  COLLATE utf8_bin NOT NULL,\n",
        "  `db_id` bigint(20) unsigned NOT NULL\n",
        ") DEFAULT CHARSET=utf8 COLLATE=utf8_bin;\n",
        "```\n",
        "\n",
        "And again you'll want to set up a primary key for the new table.\n",
        "\n",
        "```\n",
        "ALTER TABLE `postcode_data`\n",
        "ADD PRIMARY KEY (`db_id`);\n",
        "\n",
        "ALTER TABLE `postcode_data`\n",
        "MODIFY `db_id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,AUTO_INCREMENT=1;\n",
        "```\n",
        "\n",
        "And you can load the CSV file into the table using this command.\n",
        "\n",
        "```\n",
        "LOAD DATA LOCAL INFILE 'open_postcode_geo.csv' INTO TABLE `postcode_data`\n",
        "FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED by '\"'\n",
        "LINES STARTING BY '' TERMINATED BY '\\n';\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e713426d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# code to download and extract zip file\n",
        "if not os.path.exists(\"postcode_data\"):\n",
        "    os.makedirs(\"postcode_data\")\n",
        "access.download_csv(url=\"https://www.getthedata.com/downloads/open_postcode_geo.csv.zip\", filename=\"open_postcode_geo.csv.zip\", target_dir=\"postcode_data\", extract=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "82488638",
      "metadata": {},
      "outputs": [],
      "source": [
        "conn = access.create_connection(user=username, password=password, host=url, port=port, database=db_name)\n",
        "access.create_postcode_data(conn)\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2167bb1d",
      "metadata": {},
      "outputs": [],
      "source": [
        "access.populate_table(conn=conn, filename=\"postcode_data/open_postcode_geo.csv\", table=\"postcode_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "68ec53d2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(('WA8 8TU',\n",
              "  'live',\n",
              "  'small',\n",
              "  348820,\n",
              "  384408,\n",
              "  1,\n",
              "  'England',\n",
              "  Decimal('53.35406500'),\n",
              "  Decimal('-2.77037600'),\n",
              "  'WA88TU',\n",
              "  'WA8 8TU',\n",
              "  'WA8  8TU',\n",
              "  'WA',\n",
              "  'WA8',\n",
              "  'WA8 8',\n",
              "  'WA8',\n",
              "  '8TU',\n",
              "  2500000),)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check to ensure that postcode data has been populated in teh relevant table\n",
        "access.query_table(conn=conn, table='postcode_data', conditions=[access.equal_condition('db_id', 2500000)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d67ca4ef",
      "metadata": {
        "id": "d67ca4ef"
      },
      "source": [
        "### Task D\n",
        "\n",
        "This table should contain the house price paid and the latitude and longitude of the house. We could create a new data frame that contains all this information. However, the computation of that data frame would take some time because of the size of the two existing tables in the join. Whether this is a good idea or not in a live system will depend on how often these predictions are required. If it's very often, it would be better to store the join as a new table in the database, because the one-off cost for that join is amortised across all the future predictions. If only a few predictions are required (like in our lab class) then doing that join on the fly might be better.\n",
        "\n",
        "- Option A: Think about which columns from each table will be useful to you in making predictions, then write code to efficiently select this information and create a data frame from the two tables for a set of properties. \"Join on the fly\". This option looks easier but the disadvantage is the extra latency it adds as joins are performed every time we need to answer data questions. These latencies are usually not accepted in production environments.\n",
        "\n",
        "- Option B: Alternatively, you can create a database table called `property_prices` to store the join of the tables you created in the previous tasks. The advantage of this approach is that you will get faster responses because the join is performed once. The disadvantage is that populating the new table can take a long time because you would join two big tables. You need to be more creative with this option. Remember that you can divide your dataset by different criteria (e.g., by year) and that loading data from files is much faster than `INSERT INTO` instructions. Populating the table took from 4 to 6 minutes per year in our tests on a Dell Laptop Intel Core i5 with 16GB of RAM and using the Eduroam network at the Computer Lab. Populating the table by year also gives you control over the upload process. You could write your code in a way you can stop and restart the upload process. The new table could have a schema like the one below:\n",
        "\n",
        "  ```\n",
        "  USE `property_prices`;\n",
        "  --\n",
        "  -- Table structure for table `prices_coordinates_data`\n",
        "  --\n",
        "  DROP TABLE IF EXISTS `prices_coordinates_data`;\n",
        "  CREATE TABLE IF NOT EXISTS `prices_coordinates_data` (\n",
        "    `price` int(10) unsigned NOT NULL,\n",
        "    `date_of_transfer` date NOT NULL,\n",
        "    `postcode` varchar(8) COLLATE utf8_bin NOT NULL,\n",
        "    `property_type` varchar(1) COLLATE utf8_bin NOT NULL,\n",
        "    `new_build_flag` varchar(1) COLLATE utf8_bin NOT NULL,\n",
        "    `tenure_type` varchar(1) COLLATE utf8_bin NOT NULL,\n",
        "    `locality` tinytext COLLATE utf8_bin NOT NULL,\n",
        "    `town_city` tinytext COLLATE utf8_bin NOT NULL,\n",
        "    `district` tinytext COLLATE utf8_bin NOT NULL,\n",
        "    `county` tinytext COLLATE utf8_bin NOT NULL,\n",
        "    `country` enum('England', 'Wales', 'Scotland', 'Northern Ireland', 'Channel Islands', 'Isle of Man') NOT NULL,\n",
        "    `latitude` decimal(11,8) NOT NULL,\n",
        "    `longitude` decimal(10,8) NOT NULL,\n",
        "    `db_id` bigint(20) unsigned NOT NULL\n",
        "  ) DEFAULT CHARSET=utf8 COLLATE=utf8_bin AUTO_INCREMENT=1 ;\n",
        "\n",
        "  ```\n",
        "\n",
        "In both cases you will need to perform a join between `pp_data` and `postcode_data` tables. Joining large tables without the right indexes in place will take a long time. You should think and set the right index for an efficient join. Indexing the `pp_data` table should take less than 5 minutes, while it takes less than one minute to index the `postcode_data` table.\n",
        "\n",
        "Note that there is no preference for either approach in the mark scheme.\n",
        "\n",
        "You should use the joined data in your prediction model in Question 3. Exploit the nature of the task to use prices for a particular region in a given period. This means we can select the relevant rows from the database according to that region and period.\n",
        "\n",
        "***After you have populated your database tables and created the functions to access the data you need for Question 3, you will not need to redo any of the previous steps. If at some point you find the AWS database is not responding or taking longer than expected to perform operations, you can have a look at the process list and kill the one are causing problems. If killing the processes does not work, you should reboot the database in the AWS console. Be careful with other database instances if you need to reboot your database. Also, be careful not to delete the database instead of rebooting it. If you delete the database, it is likely you will need to redo all Question 1.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "Y-lttyzUtSv7",
      "metadata": {
        "id": "Y-lttyzUtSv7"
      },
      "outputs": [],
      "source": [
        "# Write the code you used to join the tables, or the code you used to join on the fly.\n",
        "# Given the fact that a real production system is likely to be latency sensitive (or at least have a preference for lower latency), I have decided to go with option B (storing the joined table ahead of time)\n",
        "# Table creation code\n",
        "conn = access.create_connection(user=username, password=password, host=url, port=port, database=db_name)\n",
        "access.create_prices_coordinates_data(conn)\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "6aa72fd3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Indexing pp_data table\n",
        "conn = access.create_connection(user=username, password=password, host=url, port=port, database=db_name)\n",
        "access.index_pp_data(conn)\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2e73a304",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Indexing postcode_data table\n",
        "conn = access.create_connection(user=username, password=password, host=url, port=port, database=db_name)\n",
        "access.index_postcode_data(conn)\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1e6a5aab",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|      | 11/29 [30:15<49:30, 165.02s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/isaacdiarrassouba/Desktop/Part II/Advanced Data Science/Final assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb Cell 31\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m cursor \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mcursor()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X44sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m cursor\u001b[39m.\u001b[39;49mexecute(\u001b[39mf\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X44sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m            SELECT price, date_of_transfer, prices.postcode, property_type, new_build_flag, tenure_type, locality, town_city, district, county, country, latitude, longitude\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X44sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m            FROM (SELECT price, date_of_transfer, postcode, property_type, new_build_flag, tenure_type, locality, town_city, district, county\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X44sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m                  FROM pp_data WHERE (date_of_transfer between \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00myear\u001b[39m}\u001b[39;49;00m\u001b[39m-01-01\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m and \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00myear\u001b[39m}\u001b[39;49;00m\u001b[39m-12-31\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m)) prices\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X44sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m            INNER JOIN (SELECT country, latitude, longitude, postcode\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X44sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m                        FROM postcode_data) postcodes\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X44sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m            ON prices.postcode = postcodes.postcode;\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X44sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m            \u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X44sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m rows \u001b[39m=\u001b[39m cursor\u001b[39m.\u001b[39mfetchall()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X44sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m file_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mjoined_data/\u001b[39m\u001b[39m{\u001b[39;00myear\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m \n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/cursors.py:153\u001b[0m, in \u001b[0;36mCursor.execute\u001b[0;34m(self, query, args)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    151\u001b[0m query \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmogrify(query, args)\n\u001b[0;32m--> 153\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query(query)\n\u001b[1;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executed \u001b[39m=\u001b[39m query\n\u001b[1;32m    155\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/cursors.py:322\u001b[0m, in \u001b[0;36mCursor._query\u001b[0;34m(self, q)\u001b[0m\n\u001b[1;32m    320\u001b[0m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_db()\n\u001b[1;32m    321\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_result()\n\u001b[0;32m--> 322\u001b[0m conn\u001b[39m.\u001b[39;49mquery(q)\n\u001b[1;32m    323\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_get_result()\n\u001b[1;32m    324\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrowcount\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:558\u001b[0m, in \u001b[0;36mConnection.query\u001b[0;34m(self, sql, unbuffered)\u001b[0m\n\u001b[1;32m    556\u001b[0m     sql \u001b[39m=\u001b[39m sql\u001b[39m.\u001b[39mencode(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding, \u001b[39m\"\u001b[39m\u001b[39msurrogateescape\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    557\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_execute_command(COMMAND\u001b[39m.\u001b[39mCOM_QUERY, sql)\n\u001b[0;32m--> 558\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_affected_rows \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_query_result(unbuffered\u001b[39m=\u001b[39;49munbuffered)\n\u001b[1;32m    559\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_affected_rows\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:822\u001b[0m, in \u001b[0;36mConnection._read_query_result\u001b[0;34m(self, unbuffered)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    821\u001b[0m     result \u001b[39m=\u001b[39m MySQLResult(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 822\u001b[0m     result\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m    823\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m result\n\u001b[1;32m    824\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mserver_status \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:1207\u001b[0m, in \u001b[0;36mMySQLResult.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_load_local_packet(first_packet)\n\u001b[1;32m   1206\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1207\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_result_packet(first_packet)\n\u001b[1;32m   1208\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1209\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnection \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:1284\u001b[0m, in \u001b[0;36mMySQLResult._read_result_packet\u001b[0;34m(self, first_packet)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfield_count \u001b[39m=\u001b[39m first_packet\u001b[39m.\u001b[39mread_length_encoded_integer()\n\u001b[1;32m   1283\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_descriptions()\n\u001b[0;32m-> 1284\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_rowdata_packet()\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:1331\u001b[0m, in \u001b[0;36mMySQLResult._read_rowdata_packet\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1329\u001b[0m rows \u001b[39m=\u001b[39m []\n\u001b[1;32m   1330\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1331\u001b[0m     packet \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnection\u001b[39m.\u001b[39;49m_read_packet()\n\u001b[1;32m   1332\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_packet_is_eof(packet):\n\u001b[1;32m   1333\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnection \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# release reference to kill cyclic reference.\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:758\u001b[0m, in \u001b[0;36mConnection._read_packet\u001b[0;34m(self, packet_type)\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[39mraise\u001b[39;00m err\u001b[39m.\u001b[39mInternalError(\n\u001b[1;32m    753\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPacket sequence number wrong - got \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m expected \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    754\u001b[0m         \u001b[39m%\u001b[39m (packet_number, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_seq_id)\n\u001b[1;32m    755\u001b[0m     )\n\u001b[1;32m    756\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_seq_id \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_seq_id \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39m256\u001b[39m\n\u001b[0;32m--> 758\u001b[0m recv_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_bytes(bytes_to_read)\n\u001b[1;32m    759\u001b[0m \u001b[39mif\u001b[39;00m DEBUG:\n\u001b[1;32m    760\u001b[0m     dump_packet(recv_data)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:779\u001b[0m, in \u001b[0;36mConnection._read_bytes\u001b[0;34m(self, num_bytes)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    778\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 779\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rfile\u001b[39m.\u001b[39mread(num_bytes)\n\u001b[1;32m    780\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
            "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.6/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Extract join data from database and store in csv locally\n",
        "# Added a check so that it does not re-extract data that has already been extracted\n",
        "if not os.path.exists(\"joined_data\"):\n",
        "    os.makedirs(\"joined_data\")\n",
        "\n",
        "for year in tqdm(range(1995, 2024)):\n",
        "      if f\"{year}.csv\" in os.listdir('joined_data'):\n",
        "            continue\n",
        "      conn = access.create_connection(user=username, password=password, host=url, port=port, database=db_name)\n",
        "      cursor = conn.cursor()\n",
        "      start = time.time()\n",
        "      cursor.execute(f\"\"\"\n",
        "                  SELECT price, date_of_transfer, prices.postcode, property_type, new_build_flag, tenure_type, locality, town_city, district, county, country, latitude, longitude\n",
        "                  FROM (SELECT price, date_of_transfer, postcode, property_type, new_build_flag, tenure_type, locality, town_city, district, county\n",
        "                        FROM pp_data WHERE (date_of_transfer between '{year}-01-01' and '{year}-12-31')) prices\n",
        "                  INNER JOIN (SELECT country, latitude, longitude, postcode\n",
        "                              FROM postcode_data) postcodes\n",
        "                  ON prices.postcode = postcodes.postcode;\n",
        "                  \"\"\")\n",
        "      rows = cursor.fetchall()\n",
        "      file_path = f'joined_data/{year}.csv' \n",
        "      with open(file_path, 'w', newline='') as csvfile:\n",
        "            csvwriter = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "            for row in rows:\n",
        "                  csvwriter.writerow(row)\n",
        "      cursor.close()\n",
        "      conn.close()\n",
        "      end = time.time()\n",
        "      print(f\"{year} took: {end-start} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "158a1af7",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|         | 1/29 [00:10<04:45, 10.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1995 took: 10.185902833938599 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|         | 2/29 [00:25<05:58, 13.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1996 took: 15.409714221954346 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|         | 3/29 [00:49<07:46, 17.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1997 took: 23.469866037368774 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|         | 3/29 [04:42<40:51, 94.28s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:1253\u001b[0m, in \u001b[0;36mMySQLResult._read_load_local_packet\u001b[0;34m(self, first_packet)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1253\u001b[0m     sender\u001b[39m.\u001b[39;49msend_data()\n\u001b[1;32m   1254\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:1423\u001b[0m, in \u001b[0;36mLoadLocalFile.send_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1422\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1423\u001b[0m             conn\u001b[39m.\u001b[39;49mwrite_packet(chunk)\n\u001b[1;32m   1424\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:727\u001b[0m, in \u001b[0;36mConnection.write_packet\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m    726\u001b[0m     dump_packet(data)\n\u001b[0;32m--> 727\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_write_bytes(data)\n\u001b[1;32m    728\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_seq_id \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_seq_id \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39m256\u001b[39m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:803\u001b[0m, in \u001b[0;36mConnection._write_bytes\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 803\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49msendall(data)\n\u001b[1;32m    804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/isaacdiarrassouba/Desktop/Part II/Advanced Data Science/Final assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb Cell 32\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X45sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X45sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m file_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mjoined_data/\u001b[39m\u001b[39m{\u001b[39;00myear\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X45sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m access\u001b[39m.\u001b[39;49mpopulate_table(conn\u001b[39m=\u001b[39;49mconn, filename\u001b[39m=\u001b[39;49mfile_path, table\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mprices_coordinates_data\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X45sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# os.remove(file_path)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X45sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/fynesse/access.py:71\u001b[0m, in \u001b[0;36mpopulate_table\u001b[0;34m(conn, filename, table)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpopulate_table\u001b[39m(conn, filename, table):\n\u001b[1;32m     70\u001b[0m     cursor \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mcursor()\n\u001b[0;32m---> 71\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(\u001b[39mf\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\n\u001b[1;32m     72\u001b[0m \u001b[39m                   LOAD DATA LOCAL INFILE \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mfilename\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m INTO TABLE \u001b[39;49m\u001b[39m{\u001b[39;49;00mtable\u001b[39m}\u001b[39;49;00m\n\u001b[1;32m     73\u001b[0m \u001b[39m                   FIELDS TERMINATED BY \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m OPTIONALLY ENCLOSED by \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     74\u001b[0m \u001b[39m                   LINES STARTING BY \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m TERMINATED BY \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m;\u001b[39;49m\n\u001b[1;32m     75\u001b[0m \u001b[39m                   \u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m)\n\u001b[1;32m     76\u001b[0m     conn\u001b[39m.\u001b[39mcommit()\n\u001b[1;32m     77\u001b[0m     cursor\u001b[39m.\u001b[39mclose()\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/cursors.py:153\u001b[0m, in \u001b[0;36mCursor.execute\u001b[0;34m(self, query, args)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    151\u001b[0m query \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmogrify(query, args)\n\u001b[0;32m--> 153\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query(query)\n\u001b[1;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executed \u001b[39m=\u001b[39m query\n\u001b[1;32m    155\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/cursors.py:322\u001b[0m, in \u001b[0;36mCursor._query\u001b[0;34m(self, q)\u001b[0m\n\u001b[1;32m    320\u001b[0m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_db()\n\u001b[1;32m    321\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_result()\n\u001b[0;32m--> 322\u001b[0m conn\u001b[39m.\u001b[39;49mquery(q)\n\u001b[1;32m    323\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_get_result()\n\u001b[1;32m    324\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrowcount\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:558\u001b[0m, in \u001b[0;36mConnection.query\u001b[0;34m(self, sql, unbuffered)\u001b[0m\n\u001b[1;32m    556\u001b[0m     sql \u001b[39m=\u001b[39m sql\u001b[39m.\u001b[39mencode(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding, \u001b[39m\"\u001b[39m\u001b[39msurrogateescape\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    557\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_execute_command(COMMAND\u001b[39m.\u001b[39mCOM_QUERY, sql)\n\u001b[0;32m--> 558\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_affected_rows \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_query_result(unbuffered\u001b[39m=\u001b[39;49munbuffered)\n\u001b[1;32m    559\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_affected_rows\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:822\u001b[0m, in \u001b[0;36mConnection._read_query_result\u001b[0;34m(self, unbuffered)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    821\u001b[0m     result \u001b[39m=\u001b[39m MySQLResult(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 822\u001b[0m     result\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m    823\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m result\n\u001b[1;32m    824\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mserver_status \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:1205\u001b[0m, in \u001b[0;36mMySQLResult.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_ok_packet(first_packet)\n\u001b[1;32m   1204\u001b[0m \u001b[39melif\u001b[39;00m first_packet\u001b[39m.\u001b[39mis_load_local_packet():\n\u001b[0;32m-> 1205\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_load_local_packet(first_packet)\n\u001b[1;32m   1206\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1207\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_result_packet(first_packet)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:1255\u001b[0m, in \u001b[0;36mMySQLResult._read_load_local_packet\u001b[0;34m(self, first_packet)\u001b[0m\n\u001b[1;32m   1253\u001b[0m     sender\u001b[39m.\u001b[39msend_data()\n\u001b[1;32m   1254\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m-> 1255\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnection\u001b[39m.\u001b[39;49m_read_packet()  \u001b[39m# skip ok packet\u001b[39;00m\n\u001b[1;32m   1256\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m   1258\u001b[0m ok_packet \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnection\u001b[39m.\u001b[39m_read_packet()\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:739\u001b[0m, in \u001b[0;36mConnection._read_packet\u001b[0;34m(self, packet_type)\u001b[0m\n\u001b[1;32m    737\u001b[0m buff \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39m()\n\u001b[1;32m    738\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 739\u001b[0m     packet_header \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_bytes(\u001b[39m4\u001b[39;49m)\n\u001b[1;32m    740\u001b[0m     \u001b[39m# if DEBUG: dump_packet(packet_header)\u001b[39;00m\n\u001b[1;32m    742\u001b[0m     btrl, btrh, packet_number \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack(\u001b[39m\"\u001b[39m\u001b[39m<HBB\u001b[39m\u001b[39m\"\u001b[39m, packet_header)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:779\u001b[0m, in \u001b[0;36mConnection._read_bytes\u001b[0;34m(self, num_bytes)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    778\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 779\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rfile\u001b[39m.\u001b[39mread(num_bytes)\n\u001b[1;32m    780\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
            "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.6/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "conn = access.create_connection(user=username, password=password, host=url, port=port, database=db_name)\n",
        "for year in tqdm(range(1995,2024)): \n",
        "        if f\"{year}.csv\" not in os.listdir('joined_data'):\n",
        "                continue\n",
        "        start = time.time()\n",
        "        file_path = f\"joined_data/{year}.csv\"\n",
        "        access.populate_table(conn=conn, filename=file_path, table=\"prices_coordinates_data\")\n",
        "        # os.remove(file_path)\n",
        "        end = time.time()\n",
        "        print(f\"{year} took: {end-start} seconds\")\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "05e1e249",
      "metadata": {},
      "outputs": [
        {
          "ename": "ProgrammingError",
          "evalue": "(1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near '' at line 1\")",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[1;32m/Users/isaacdiarrassouba/Desktop/Part II/Advanced Data Science/Final assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb Cell 33\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m conn \u001b[39m=\u001b[39m access\u001b[39m.\u001b[39mcreate_connection(user\u001b[39m=\u001b[39musername, password\u001b[39m=\u001b[39mpassword, host\u001b[39m=\u001b[39murl, port\u001b[39m=\u001b[39mport, database\u001b[39m=\u001b[39mdb_name)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/isaacdiarrassouba/Desktop/Part%20II/Advanced%20Data%20Science/Final%20assignment/fynesse_template/notebooks/ADS_Report_2268A.ipynb#X46sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m access\u001b[39m.\u001b[39;49mquery_table(conn, \u001b[39m'\u001b[39;49m\u001b[39mprices_coordinates_data\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/fynesse/access.py:93\u001b[0m, in \u001b[0;36mquery_table\u001b[0;34m(conn, table, fields, conditions)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mquery_table\u001b[39m(conn, table, fields\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m], conditions\u001b[39m=\u001b[39m[]):\n\u001b[1;32m     92\u001b[0m     cursor \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mcursor()\n\u001b[0;32m---> 93\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(\u001b[39mf\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\n\u001b[1;32m     94\u001b[0m \u001b[39m                   SELECT \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(fields)\u001b[39m}\u001b[39;49;00m\u001b[39m FROM \u001b[39;49m\u001b[39m{\u001b[39;49;00mtable\u001b[39m}\u001b[39;49;00m\u001b[39m WHERE \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39mAND \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(conditions)\u001b[39m}\u001b[39;49;00m\u001b[39m; \u001b[39;49m\n\u001b[1;32m     95\u001b[0m \u001b[39m                   \u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m)\n\u001b[1;32m     96\u001b[0m     conn\u001b[39m.\u001b[39mcommit()\n\u001b[1;32m     97\u001b[0m     result \u001b[39m=\u001b[39m cursor\u001b[39m.\u001b[39mfetchall()\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/cursors.py:153\u001b[0m, in \u001b[0;36mCursor.execute\u001b[0;34m(self, query, args)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    151\u001b[0m query \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmogrify(query, args)\n\u001b[0;32m--> 153\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query(query)\n\u001b[1;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executed \u001b[39m=\u001b[39m query\n\u001b[1;32m    155\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/cursors.py:322\u001b[0m, in \u001b[0;36mCursor._query\u001b[0;34m(self, q)\u001b[0m\n\u001b[1;32m    320\u001b[0m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_db()\n\u001b[1;32m    321\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_result()\n\u001b[0;32m--> 322\u001b[0m conn\u001b[39m.\u001b[39;49mquery(q)\n\u001b[1;32m    323\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_get_result()\n\u001b[1;32m    324\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrowcount\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:558\u001b[0m, in \u001b[0;36mConnection.query\u001b[0;34m(self, sql, unbuffered)\u001b[0m\n\u001b[1;32m    556\u001b[0m     sql \u001b[39m=\u001b[39m sql\u001b[39m.\u001b[39mencode(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding, \u001b[39m\"\u001b[39m\u001b[39msurrogateescape\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    557\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_execute_command(COMMAND\u001b[39m.\u001b[39mCOM_QUERY, sql)\n\u001b[0;32m--> 558\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_affected_rows \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_query_result(unbuffered\u001b[39m=\u001b[39;49munbuffered)\n\u001b[1;32m    559\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_affected_rows\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:822\u001b[0m, in \u001b[0;36mConnection._read_query_result\u001b[0;34m(self, unbuffered)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    821\u001b[0m     result \u001b[39m=\u001b[39m MySQLResult(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 822\u001b[0m     result\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m    823\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m result\n\u001b[1;32m    824\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mserver_status \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:1200\u001b[0m, in \u001b[0;36mMySQLResult.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1200\u001b[0m         first_packet \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnection\u001b[39m.\u001b[39;49m_read_packet()\n\u001b[1;32m   1202\u001b[0m         \u001b[39mif\u001b[39;00m first_packet\u001b[39m.\u001b[39mis_ok_packet():\n\u001b[1;32m   1203\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_ok_packet(first_packet)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/connections.py:772\u001b[0m, in \u001b[0;36mConnection._read_packet\u001b[0;34m(self, packet_type)\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39munbuffered_active \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    771\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39munbuffered_active \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 772\u001b[0m     packet\u001b[39m.\u001b[39;49mraise_for_error()\n\u001b[1;32m    773\u001b[0m \u001b[39mreturn\u001b[39;00m packet\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/protocol.py:221\u001b[0m, in \u001b[0;36mMysqlPacket.raise_for_error\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[39mif\u001b[39;00m DEBUG:\n\u001b[1;32m    220\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39merrno =\u001b[39m\u001b[39m\"\u001b[39m, errno)\n\u001b[0;32m--> 221\u001b[0m err\u001b[39m.\u001b[39;49mraise_mysql_exception(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pymysql/err.py:143\u001b[0m, in \u001b[0;36mraise_mysql_exception\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m errorclass \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     errorclass \u001b[39m=\u001b[39m InternalError \u001b[39mif\u001b[39;00m errno \u001b[39m<\u001b[39m \u001b[39m1000\u001b[39m \u001b[39melse\u001b[39;00m OperationalError\n\u001b[0;32m--> 143\u001b[0m \u001b[39mraise\u001b[39;00m errorclass(errno, errval)\n",
            "\u001b[0;31mProgrammingError\u001b[0m: (1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near '' at line 1\")"
          ]
        }
      ],
      "source": [
        "conn = access.create_connection(user=username, password=password, host=url, port=port, database=db_name)\n",
        "access.query_table(conn, 'prices_coordinates_data')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df36e5d1",
      "metadata": {
        "id": "df36e5d1"
      },
      "source": [
        "## Question 2. Accessing OpenStreetMap and Assessing the Available Features\n",
        "\n",
        "In question 3 you will be given the task of constructing a prediction system for property price levels at a given location. We expect that knowledge of the local region around the property should be helpful in making those price predictions. To evaluate this we will now look at [OpenStreetMap](https://www.openstreetmap.org) as a data source.\n",
        "\n",
        "The tasks below will guide you in accessing and assessing the OpenStreetMap data. The code you write will eventually be assimilated in your python module, but documentation of what you've included and why should remain in the notebook below.\n",
        "\n",
        "Accessing OpenStreetMap through its API can be done using the python library `osmx`. Using what you have learned about the `osmx` interface in the lectures, write general code for downloading points of interest and other relevant information that you believe may be useful for predicting house prices. Remembering the perspectives we've taken on *data science as debugging*, the remarks we've made when discussing *the data crisis* of the importance of reusability in data analysis, and the techniques we've explored in the labsessions for visualising features and exploring their correlation use the notebook to document your assessment of the OpenStreetMap data as a potential source of data.\n",
        "\n",
        "The knowledge you need to do a first pass through this question will have been taught by end of lab session three (16th November 2021). You will likely want to review your answer as part of *refactoring* your code and analysis pipeline shortly before hand in.\n",
        "\n",
        "You should write reusable code that allows you to explore the characteristics of different points of interest. Looking ahead to question 3 you'll want to incorporate these points of interest in your prediction code.\n",
        "\n",
        "*5 marks*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "042a2863",
      "metadata": {
        "id": "042a2863"
      },
      "outputs": [],
      "source": [
        "# Use this cell and cells below for summarising your analysis and documenting your decision making.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09a0e365",
      "metadata": {
        "id": "09a0e365"
      },
      "source": [
        "## Question 3. Addressing a Property Price Prediction Question\n",
        "\n",
        "For your final tick, we will be asking you to make house price predictions for a given location, date and property type in the UK. You will provide a function that takes input a latitude and longitude as well as the `property_type` (either type\" of property (either `F` - flat, `S` - semidetached, `D` - detached, `T` - terraced or `O` other). Create this function in the `address.py` file, for example in the form,\n",
        "\n",
        "```\n",
        "def predict_price(latitude, longitude, date, property_type):\n",
        "    \"\"\"Price prediction for UK housing.\"\"\"\n",
        "    pass\n",
        "```\n",
        "\n",
        "We suggest that you use the following approach when building your prediction.\n",
        "\n",
        "1. Select a bounding box around the housing location in latitude and longitude.\n",
        "2. Select a data range around the prediction date.\n",
        "3. Use the data ecosystem you have build above to build a training set from the relevant time period and location in the UK. Include appropriate features from OSM to improve the prediction.\n",
        "4. Train a linear model on the data set you have created.\n",
        "5. Validate the quality of the model.\n",
        "6. Provide a prediction of the price from the model, warning appropriately if your validation indicates the quality of the model is poor.\n",
        "\n",
        "Please note that the quality of predictions is not the main focus of the assignment - we expect to see models that output reasonable predictions and have positive R^2's, but you should not spend too much time on increasing the model's accuracy.\n",
        "\n",
        "The knowledge you need to do a first pass through this question will have been taught by end of lab session four (7th November 2023). You will likely want to review your answer as part of *refactoring* your code shortly before hand in.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Si3K0A2zM7pa",
      "metadata": {
        "id": "Si3K0A2zM7pa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "eEDpLiW0Zr_L",
      "metadata": {
        "id": "eEDpLiW0Zr_L"
      },
      "source": [
        "## Large Language Models\n",
        "\n",
        "If you used LLMs to generate or fix code in this assignment (recommended), briefly summarise the process and prompts you used. What do you think of the integration of LLMs in the data science pipeline?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "osdBm1BNaHL1",
      "metadata": {
        "id": "osdBm1BNaHL1"
      },
      "source": [
        "```GIVE YOUR WRITTEN ANSWER HERE```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DJDQPmkLldvp",
      "metadata": {
        "id": "DJDQPmkLldvp"
      },
      "source": [
        "### FAQs\n",
        "\n",
        "- Why is my connection to the AWS server intermittent?\n",
        "\n",
        "If you are using Google Colab, online notebooks may throttle your code or time you out. Local Python code is recommended for tasks for large data management in the database.\n",
        "\n",
        "- Why do SQL queries take a long time?\n",
        "\n",
        "Some queries legitimately take a long time, even when done right. We suggest indexing your tables to speed up queries over your database. You can index tables by different columns depending on the queries you want to perform. For example, indexing the tables by `postcode` could speed up the join in Task D. More information regarding indexing in MariaDB is available [here](https://mariadb.com/kb/en/getting-started-with-indexes/).\n",
        "\n",
        "You may also want to consider creating single or multi-column indices on coordinates, or any other properties you use to select data, if that step is taking a long time.\n",
        "\n",
        "If your new queries seem stuck, try running `SHOW FULL PROCESSLIST`, and `KILL` any stuck processes.\n",
        "\n",
        "- Why are table populating processes taking so long?\n",
        "\n",
        "Again populating the database can take long. However, be careful if you are indexing the tables. You should populate data before indexing. Insert operations are impacted by indexes as they are updated with each new row inserted into the table.\n",
        "\n",
        "- Some other questions are answered in [this reddit forum](https://www.reddit.com/r/CST_ADS/) or [this doc](https://docs.google.com/document/d/1GfDROyUW8HVs2eyxmJzKrYGRdVyUiVXzPcDfwOO8wX0/edit?usp=sharing). Feel free to also ask about anything that comes up."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
